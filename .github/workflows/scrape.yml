name: GBFS Scraper

# Trigger every 10 minutes
on:
  schedule:
    - cron: '*/10 * * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1) Grab your repo code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2) Install Python
      - name: Set up Python 3.x
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      # 3) Install dependencies
      - name: Install requests
        run: pip install requests

      # 4) Run the scraper script (no loop/sleep inside!)
      - name: Run GBFS scraper
        run: python bikeshare_scraper.py

      # 5) Upload CSVs even if the script failed
      - name: Upload CSV logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gbfs-logs
          path: |
            station_status_log.csv
            free_bikes_log.csv
